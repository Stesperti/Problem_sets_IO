{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a656a7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyblp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from numpy.random import default_rng\n",
    "from scipy.optimize import root\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from linearmodels.iv import IV2SLS\n",
    "from pathlib import Path\n",
    "\n",
    "pyblp.options.digits = 2\n",
    "pyblp.options.verbose = False\n",
    "pyblp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b655c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foc_norm(p, x_t, xi_t, mc_t):\n",
    "    r = foc_residuals(p, x_t, xi_t, mc_t)\n",
    "    return np.max(np.abs(r)), r\n",
    "\n",
    "def ms_mapping_gap(p, x_t, xi_t, mc_t):\n",
    "    s, dsdp = sim_shares_and_jacobian(p, x_t, xi_t)\n",
    "    gap = p - (mc_t - s / np.diag(dsdp))  # zero at fixed point\n",
    "    return np.max(np.abs(gap)), gap\n",
    "\n",
    "def sim_shares_and_jacobian(p_t, x_t, xi_t):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    p_t  : (J,) prices in market t\n",
    "    x_t  : (J,) quality draws for market t\n",
    "    xi_t : (J,) demand unobservable for market t\n",
    "    Returns:\n",
    "    s_mean : (J,) simulated market shares (inside goods)\n",
    "    dsdp   : (J, J) Jacobian ds_j/dp_k\n",
    "    Details:\n",
    "    Individual utility (up to i.i.d. EV1): v_ij = TRUE_BETA1*x_j + beta2_i*sat_j + beta3_i*wir_j + TRUE_ALPHA*p_j + xi_j\n",
    "    s_ij = exp(v_ij) / (1 + sum_k exp(v_ik))  (outside utility normalized to 0)\n",
    "    Aggregate s_j = E_i[s_ij] via R-draw simulation.\n",
    "    Derivative under the integral (per draw): ∂s_ij/∂p_k = TRUE_ALPHA * s_ij * (1{j=k} - s_ik)\n",
    "    => dsdp[j,k] = E_i[ ∂s_ij/∂p_k ] (Monte Carlo average).\n",
    "    \"\"\"\n",
    "    # v_i (R,J): random coeffs enter via sat/wir dummies\n",
    "    v = (TRUE_BETA1 * x_t[None, :]\n",
    "        + beta2_draws[:, None] * is_sat[None, :]\n",
    "        + beta3_draws[:, None] * is_wir[None, :]\n",
    "        + TRUE_ALPHA * p_t[None, :]\n",
    "        + xi_t[None, :])  # shape (R, J)\n",
    "\n",
    "    exp_v = np.exp(v - np.max(v, axis=1, keepdims=True))  # safe stab.\n",
    "    denom = 1.0 + np.sum(exp_v, axis=1, keepdims=True)    # add outside option\n",
    "    s_ind = exp_v / denom                                 # (R, J)\n",
    "    s_mean = s_ind.mean(axis=0)                           # (J,)\n",
    "\n",
    "    # Jacobian: ds_j/dp_k = E_i[ TRUE_ALPHA * s_ij * (1{j=k} - s_ik) ]\n",
    "    dsdp = np.empty((J, J))\n",
    "    for k in range(J):\n",
    "        factor = TRUE_ALPHA * (np.eye(J)[k][None, :] - s_ind)  \n",
    "        dsdp[:, k] = np.mean(s_ind * factor, axis=0)\n",
    "    return s_mean, dsdp\n",
    "\n",
    "def foc_residuals(p_t, x_t, xi_t, mc_t):\n",
    "    s, dsdp = sim_shares_and_jacobian(p_t, x_t, xi_t)\n",
    "    # Single-product FOCs: (p_j - mc_j)*ds_j/dp_j + s_j = 0  for each j\n",
    "    diag = np.diag(dsdp)  \n",
    "    return (p_t - mc_t) * diag + s\n",
    "\n",
    "def solve_equilibrium_root(x_t, xi_t, mc_t, p0=None, tol=1e-12):\n",
    "    # Root-finding on the J FOCs\n",
    "    if p0 is None:\n",
    "        p0 = mc_t + 1.0  # mild markup starting point\n",
    "    sol = root(lambda p: foc_residuals(p, x_t, xi_t, mc_t), p0, method='hybr', tol=tol)\n",
    "    return sol.x, sol.success, sol.nfev\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Morrow–Skerlos Fixed-Point (MSFP) mapping per market\n",
    "# ------------------------------------------------------\n",
    "def msfp_prices(x_t, xi_t, mc_t, p0=None, max_iter=5000, tol=1e-10, damp=0.8):\n",
    "    \"\"\"\n",
    "    p_{n+1} = mc - diag(dsdp(p_n))^{-1} s(p_n)\n",
    "    Optional damping for stability.\n",
    "    \"\"\"\n",
    "    if p0 is None:\n",
    "        p = mc_t + 1.0\n",
    "    else:\n",
    "        p = p0.copy()\n",
    "    for it in range(max_iter):\n",
    "        s, dsdp = sim_shares_and_jacobian(p, x_t, xi_t)\n",
    "        diag = np.diag(dsdp)\n",
    "        # Guard: own-prices derivatives should be negative\n",
    "        if np.any(diag >= 0):\n",
    "            # If happens, try to bail with small step toward mc\n",
    "            p = 0.5 * (p + mc_t)\n",
    "            continue\n",
    "        p_new = mc_t - s / diag\n",
    "        # damping\n",
    "        p_next = damp * p_new + (1.0 - damp) * p\n",
    "        # convergence\n",
    "        if np.max(np.abs(p_next - p)) < tol:\n",
    "            return p_next, True, it + 1\n",
    "        p = p_next\n",
    "    return p, False, max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c35a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-solver success: 1.000 of markets\n",
      "MSFP success:        1.000 of markets\n",
      "Max |price_root - price_msfp|: 2.318145675417327e-13\n",
      "Root solution:  max FOC residual = 5.551115123125783e-17  | max MS gap = 4.440892098500626e-16\n",
      "MSFP solution:  max FOC residual = 7.210898544940392e-14  | max MS gap = 1.6120438317557273e-13\n",
      "max |p_root - p_msfp| = 1.6120438317557273e-13\n",
      "   market_ids  product_ids  is_satellite  is_wired         x         w  \\\n",
      "0           1            1             1         0  1.423825  1.065850   \n",
      "1           1            2             1         0  1.263728  0.309725   \n",
      "2           1            3             0         1  0.870662  0.051537   \n",
      "3           1            4             0         1  0.259173  1.372945   \n",
      "4           2            1             1         0  0.075343  0.137299   \n",
      "\n",
      "         xi     omega        mc    prices    shares  \n",
      "0 -0.578893  0.554603  2.306631  2.830617  0.042903  \n",
      "1  1.305041 -0.000393  1.781369  2.611541  0.372759  \n",
      "2 -1.340123 -0.923868  1.487952  2.055257  0.070369  \n",
      "3  0.874820 -1.406342  1.949248  2.579493  0.122576  \n",
      "4  0.829740  0.077598  1.722927  2.388093  0.163739  \n"
     ]
    }
   ],
   "source": [
    "rng = default_rng(12345)  # reproducible\n",
    "T = 600                    # markets\n",
    "J = 4                      \n",
    "R = 100              \n",
    "# Demand parameters\n",
    "TRUE_BETA1 = 1.0                \n",
    "TRUE_ALPHA = -2.0               \n",
    "# random coefficients: beta2_i ~ N(4,1) on satellite, beta3_i ~ N(4,1) on wired\n",
    "TRUE_MU2, TRUE_SD2 = 4.0, 1.0\n",
    "TRUE_MU3, TRUE_SD3 = 4.0, 1.0\n",
    "# Cost parameters\n",
    "gamma0 = 0.5\n",
    "gamma1 = 0.25\n",
    "# Correlated unobservables (xi, omega): N(0,0; 1, 0.25; 0.25, 1)\n",
    "Sigma = np.array([[1.0, 0.25],\n",
    "                [0.25, 1.0]])\n",
    "# Product identities: j=0,1 are satellite; j=2,3 are wired\n",
    "is_sat = np.array([1, 1, 0, 0], dtype=int)\n",
    "is_wir = 1 - is_sat\n",
    "\n",
    "# Exogenous characteristics and cost shifter: abs(N(0,1))\n",
    "x = np.abs(rng.standard_normal((T, J)))\n",
    "w = np.abs(rng.standard_normal((T, J)))\n",
    "\n",
    "z = rng.multivariate_normal(mean=np.zeros(2), cov=Sigma, size=T*J)\n",
    "xi = z[:, 0].reshape(T, J)\n",
    "omega = z[:, 1].reshape(T, J)\n",
    "\n",
    "# Marginal costs: ln mc_jt = gamma0 + gamma1 * w_jt + omega_jt/8\n",
    "mc = np.exp(gamma0 + gamma1 * w + omega / 8.0)  # shape (T, J)\n",
    "\n",
    "beta2_draws = TRUE_MU2 + TRUE_SD2 * rng.standard_normal(R)   # satellite taste\n",
    "beta3_draws = TRUE_MU3 + TRUE_SD3 * rng.standard_normal(R)   # wired taste\n",
    "\n",
    "# -------------------------\n",
    "prices_root = np.empty((T, J))\n",
    "succ_root   = np.zeros(T, dtype=bool)\n",
    "evals_root  = np.zeros(T, dtype=int)\n",
    "\n",
    "prices_msfp = np.empty((T, J))\n",
    "succ_msfp   = np.zeros(T, dtype=bool)\n",
    "iters_msfp  = np.zeros(T, dtype=int)\n",
    "\n",
    "for t in range(T):\n",
    "    # Root-solver\n",
    "\n",
    "    # MSFP, warm-start at root solution (or mc+1 if root failed)\n",
    "    p0 = (mc[t] + 1.0)\n",
    "    p_ms, ok_ms, it_ms = msfp_prices(x[t], xi[t], mc[t], p0=p0, max_iter=2000, tol=1e-12, damp=0.85)\n",
    "    prices_msfp[t] = p_ms\n",
    "    succ_msfp[t] = ok_ms\n",
    "    iters_msfp[t] = it_ms\n",
    "\n",
    "    p_star, ok, nfev = solve_equilibrium_root(x[t], xi[t], mc[t], p0=p_ms)\n",
    "    prices_root[t] = p_star\n",
    "    succ_root[t] = ok\n",
    "    evals_root[t] = nfev\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "shares_root = np.empty((T, J))\n",
    "shares_msfp = np.empty((T, J))\n",
    "for t in range(T):\n",
    "    s_r, _ = sim_shares_and_jacobian(prices_root[t], x[t], xi[t])\n",
    "    s_m, _ = sim_shares_and_jacobian(prices_msfp[t], x[t], xi[t])\n",
    "    shares_root[t] = s_r\n",
    "    shares_msfp[t] = s_m\n",
    "\n",
    "# -------------------------\n",
    "print(f\"Root-solver success: {succ_root.mean():.3f} of markets\")\n",
    "print(f\"MSFP success:        {succ_msfp.mean():.3f} of markets\")\n",
    "\n",
    "# Compare the two methods (they should match very closely if both converged)\n",
    "diff = np.abs(prices_root - prices_msfp)\n",
    "print(\"Max |price_root - price_msfp|:\", np.nanmax(diff))\n",
    "\n",
    "t = 0  # pick a market to inspect\n",
    "p_r = prices_root[t]\n",
    "p_m = prices_msfp[t]\n",
    "\n",
    "fn_r, rvec_r = foc_norm(p_r, x[t], xi[t], mc[t])\n",
    "fn_m, rvec_m = foc_norm(p_m, x[t], xi[t], mc[t])\n",
    "mg_r, gvec_r = ms_mapping_gap(p_r, x[t], xi[t], mc[t])\n",
    "mg_m, gvec_m = ms_mapping_gap(p_m, x[t], xi[t], mc[t])\n",
    "\n",
    "print(\"Root solution:  max FOC residual =\", fn_r, \" | max MS gap =\", mg_r)\n",
    "print(\"MSFP solution:  max FOC residual =\", fn_m, \" | max MS gap =\", mg_m)\n",
    "print(\"max |p_root - p_msfp| =\", np.max(np.abs(p_r - p_m)))\n",
    "\n",
    "# Optional: assemble a tidy DataFrame to export\n",
    "records = []\n",
    "for t in range(T):\n",
    "    for j in range(J):\n",
    "        nest_ids = 1 if (j + 1 ) == 1 or (j + 1) == 0 else 1\n",
    "        records.append({\n",
    "            \"market_ids\": t+1,\n",
    "            \"product_ids\": j+1,\n",
    "            #\"nesting_ids\": nest_ids,\n",
    "            \"is_satellite\": is_sat[j],\n",
    "            \"is_wired\": is_wir[j],\n",
    "            \"x\": x[t, j],\n",
    "            \"w\": w[t, j],\n",
    "            \"xi\": xi[t, j],\n",
    "            \"omega\": omega[t, j],\n",
    "            \"mc\": mc[t, j],\n",
    "            \"prices\": prices_root[t, j],\n",
    "            \"shares\": shares_root[t, j],\n",
    "        })\n",
    "data = pd.DataFrame.from_records(records)\n",
    "for c in data.columns:\n",
    "    data[c] = pd.to_numeric(data[c])\n",
    "data.to_csv(\"simulated_data.csv\", index=False)\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd94ce1",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69da433a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.933\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.933\n",
      "Method:                 Least Squares   F-statistic:                          1.119e+04\n",
      "Date:                Fri, 24 Oct 2025   Prob (F-statistic):                        0.00\n",
      "Time:                        17:58:29   Log-Likelihood:                         -3054.9\n",
      "No. Observations:                2400   AIC:                                      6116.\n",
      "Df Residuals:                    2397   BIC:                                      6133.\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.5562      0.028     19.603      0.000       0.501       0.612\n",
      "x2             0.0421      0.035      1.205      0.228      -0.026       0.111\n",
      "x3            -1.3529      0.012   -108.417      0.000      -1.377      -1.328\n",
      "==============================================================================\n",
      "Omnibus:                      163.154   Durbin-Watson:                   2.178\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              215.424\n",
      "Skew:                          -0.604   Prob(JB):                     1.66e-47\n",
      "Kurtosis:                       3.834   Cond. No.                         5.86\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "ln_s_0t = - np.log(1.0 - shares_root.sum(axis=1))  # (T,)\n",
    "diff_ln_s_jt = np.log(shares_root) - np.repeat(ln_s_0t[:, None], J, axis=1)  # (T,J)\n",
    "\n",
    "diff_ln_s_jt_vec = diff_ln_s_jt.flatten()  # (T*J,)\n",
    "\n",
    "X = [data['x'].values, data[\"is_satellite\"].values, data['prices'].values]\n",
    "X_mat = np.column_stack(X)\n",
    "model = sm.OLS(diff_ln_s_jt_vec, X_mat)\n",
    "results_OLS = model.fit()\n",
    "print(results_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9389ff1",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb92f0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                      0.9329\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.9328\n",
      "No. Observations:                2400   F-statistic:                 2.841e+04\n",
      "Date:                Fri, Oct 24 2025   P-value (F-stat)                0.0000\n",
      "Time:                        17:58:29   Distribution:                  chi2(3)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                              Parameter Estimates                               \n",
      "================================================================================\n",
      "              Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "--------------------------------------------------------------------------------\n",
      "x                0.6371     0.0345     18.478     0.0000      0.5695      0.7047\n",
      "is_satellite     0.1198     0.0414     2.8897     0.0039      0.0385      0.2010\n",
      "prices          -1.4047     0.0202    -69.450     0.0000     -1.4444     -1.3651\n",
      "================================================================================\n",
      "\n",
      "Endogenous: prices\n",
      "Instruments: w\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "data_IV = pd.DataFrame({\n",
    "    \"y\":        pd.Series(diff_ln_s_jt_vec).astype(float),\n",
    "    \"x\":        pd.Series(data[\"x\"]).astype(float),\n",
    "    \"prices\":   pd.Series(data[\"prices\"]).astype(float),\n",
    "    \"w\":        pd.Series(data[\"w\"]).astype(float),\n",
    "    \"is_satellite\": pd.Series(data[\"is_satellite\"]).astype(int)  # 0/1\n",
    "}).dropna()\n",
    "\n",
    "results_IV = IV2SLS.from_formula(\n",
    "    \"y ~ x + is_satellite + [prices ~ w]\",\n",
    "    data=data_IV\n",
    ").fit(cov_type=\"robust\")\n",
    "\n",
    "print(results_IV.summary)   # note: no parentheses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb4eaed9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'Jinja2'. DataFrame.style requires jinja2. Use pip or conda to install Jinja2.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/compat/_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/importlib/__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'jinja2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# 5) Write LaTeX to file\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m     59\u001b[39m out_path = Path(\u001b[33m\"\u001b[39m\u001b[33mlatex/table_exercise_4.tex\u001b[39m\u001b[33m\"\u001b[39m).resolve()\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m latex_str = \u001b[43mtable_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_latex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%.3f\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_format\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlccc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcaption\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTrue parameters vs. OLS and IV-2SLS estimates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtab:exercise_4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescape\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     67\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m out_path.write_text(latex_str, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mLaTeX table written to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py:3685\u001b[39m, in \u001b[36mNDFrame.to_latex\u001b[39m\u001b[34m(self, buf, columns, header, index, na_rep, formatters, float_format, sparsify, index_names, bold_rows, column_format, longtable, escape, encoding, decimal, multicolumn, multicolumn_format, multirow, caption, label, position)\u001b[39m\n\u001b[32m   3663\u001b[39m     hide_.append({\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33maxis\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m   3665\u001b[39m render_kwargs_ = {\n\u001b[32m   3666\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhrules\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   3667\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msparse_index\u001b[39m\u001b[33m\"\u001b[39m: sparsify,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3682\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbold_rows\u001b[39m\u001b[33m\"\u001b[39m: bold_rows,\n\u001b[32m   3683\u001b[39m }\n\u001b[32m-> \u001b[39m\u001b[32m3685\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_latex_via_styler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhide\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhide_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrelabel_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelabel_index_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3689\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mformatter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatters_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbase_format_\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mformat_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformat_index_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrender_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrender_kwargs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3692\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py:3742\u001b[39m, in \u001b[36mNDFrame._to_latex_via_styler\u001b[39m\u001b[34m(self, buf, hide, relabel_index, format, format_index, render_kwargs)\u001b[39m\n\u001b[32m   3694\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   3695\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_to_latex_via_styler\u001b[39m(\n\u001b[32m   3696\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3703\u001b[39m     render_kwargs: \u001b[38;5;28mdict\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   3704\u001b[39m ):\n\u001b[32m   3705\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3706\u001b[39m \u001b[33;03m    Render object to a LaTeX tabular, longtable, or nested table.\u001b[39;00m\n\u001b[32m   3707\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3740\u001b[39m \u001b[33;03m        If buf is None, returns the result as a string. Otherwise returns None.\u001b[39;00m\n\u001b[32m   3741\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3742\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstyle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Styler\n\u001b[32m   3744\u001b[39m     \u001b[38;5;28mself\u001b[39m = cast(\u001b[33m\"\u001b[39m\u001b[33mDataFrame\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m   3745\u001b[39m     styler = Styler(\u001b[38;5;28mself\u001b[39m, uuid=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/formats/style.py:44\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mshared_docs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _shared_docs\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m save_to_buffer\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m jinja2 = \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjinja2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDataFrame.style requires jinja2.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstyle_render\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     47\u001b[39m     CSSProperties,\n\u001b[32m     48\u001b[39m     CSSStyles,\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m     refactor_levels,\n\u001b[32m     57\u001b[39m )\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/compat/_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Missing optional dependency 'Jinja2'. DataFrame.style requires jinja2. Use pip or conda to install Jinja2."
     ]
    }
   ],
   "source": [
    "def grab(series_like, name):\n",
    "    \"\"\"Safely pick coefficient by name; return NaN if missing.\"\"\"\n",
    "    try:\n",
    "        return float(series_like[name])\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "row_order = [\n",
    "    (\"$\\\\alpha (price)$\", \"prices\"),\n",
    "    (\"$\\\\beta_1 (x)$\", \"x\"),\n",
    "    (\"$\\\\beta_2 (is_satellite)$\", \"is_satellite\")\n",
    "]\n",
    "\n",
    "table_data = pd.DataFrame(\n",
    "    {\n",
    "        \"True value\": [\n",
    "            TRUE_ALPHA,\n",
    "            TRUE_BETA1,\n",
    "            TRUE_MU2\n",
    "        ],\n",
    "        \"OLS\": [\n",
    "            results_OLS.params[2],\n",
    "            results_OLS.params[0],\n",
    "            results_OLS.params[1],\n",
    "        ],\n",
    "        \"IV-2SLS (robust)\": [\n",
    "            grab(results_IV.params, \"prices\"),\n",
    "            grab(results_IV.params, \"x\"),\n",
    "            grab(results_IV.params, \"is_satellite\"),\n",
    "        ],\n",
    "    },\n",
    "    index=[r[0] for r in row_order],\n",
    ").astype(float)\n",
    "\n",
    "# (Optional) add SEs as extra rows; comment out if you prefer a compact table\n",
    "add_ses = True\n",
    "if add_ses:\n",
    "    se_rows = pd.DataFrame(\n",
    "        {\n",
    "            \"True value\": [\"\", \"\", \"\"],\n",
    "            \"OLS\": [\n",
    "                results_OLS.bse[2],\n",
    "                results_OLS.bse[0],\n",
    "                results_OLS.bse[1],\n",
    "            ],\n",
    "            \"IV-2SLS (robust)\": [\n",
    "                grab(results_IV.std_errors, \"prices\"),\n",
    "                grab(results_IV.std_errors, \"x\"),\n",
    "                grab(results_IV.std_errors, \"is_satellite\"),\n",
    "            ],\n",
    "        },\n",
    "        index=[r + \" (s.e.)\" for r in [ro[0] for ro in row_order]],\n",
    "    )\n",
    "    table_data = pd.concat([table_data, se_rows], axis=0)\n",
    "\n",
    "# ===============================\n",
    "# 5) Write LaTeX to file\n",
    "# ===============================\n",
    "out_path = Path(\"latex/table_exercise_4.tex\").resolve()\n",
    "latex_str = table_data.to_latex(\n",
    "    index=True,\n",
    "    float_format=\"%.3f\",\n",
    "    column_format=\"lccc\",\n",
    "    caption=\"True parameters vs. OLS and IV-2SLS estimates\",\n",
    "    label=\"tab:exercise_4\",\n",
    "    escape=False\n",
    ")\n",
    "out_path.write_text(latex_str, encoding=\"utf-8\")\n",
    "print(f\"\\nLaTeX table written to: {out_path}\")\n",
    "\n",
    "# If you prefer to also save a CSV for quick checking:\n",
    "table_data.to_csv(\"latex/table_exercise_4.csv\", index=True)\n",
    "print(\"CSV written to: latex/table_exercise_4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd018495",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db402e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"simulated_data.csv\")\n",
    "\n",
    "# 1) Outside share and log share ratio\n",
    "mkt_sum = data.groupby(\"market_ids\")[\"shares\"].sum().rename(\"sum_share_mkt\")\n",
    "data = data.merge(mkt_sum, on=\"market_ids\", how=\"left\")\n",
    "data[\"s0\"] = (1.0 - data[\"sum_share_mkt\"]).clip(lower=1e-12)\n",
    "data[\"ln_sj_s0\"] = np.log(data[\"shares\"].clip(lower=1e-12)) - np.log(data[\"s0\"])\n",
    "\n",
    "# 2) Boolean masks for nests\n",
    "mask_sat = data[\"is_satellite\"].astype(bool)\n",
    "mask_wir = data[\"is_wired\"].astype(bool)\n",
    "\n",
    "# 3) Nest totals S_{g,t}\n",
    "S_sat = (data.assign(sat_share=np.where(mask_sat, data[\"shares\"], 0.0))\n",
    "           .groupby(\"market_ids\")[\"sat_share\"].transform(\"sum\"))\n",
    "S_wir = (data.assign(wir_share=np.where(mask_wir, data[\"shares\"], 0.0))\n",
    "           .groupby(\"market_ids\")[\"wir_share\"].transform(\"sum\"))\n",
    "\n",
    "# 4) Within-nest logs (0 for products not in that nest)\n",
    "data[\"ln_within_sat\"] = 0.0\n",
    "valid_sat = mask_sat & (S_sat > 0)\n",
    "data.loc[valid_sat, \"ln_within_sat\"] = np.log((data.loc[valid_sat, \"shares\"] / S_sat[valid_sat]).clip(lower=1e-12))\n",
    "\n",
    "data[\"ln_within_wired\"] = 0.0\n",
    "valid_wir = mask_wir & (S_wir > 0)\n",
    "data.loc[valid_wir, \"ln_within_wired\"] = np.log((data.loc[valid_wir, \"shares\"] / S_wir[valid_wir]).clip(lower=1e-12))\n",
    "\n",
    "\n",
    "formula = (\n",
    "    \"ln_sj_s0 ~  x + ln_within_sat + ln_within_wired \"\n",
    "    \"[prices ~ w]\"\n",
    ")\n",
    "iv_res = IV2SLS.from_formula(formula, data=data).fit(\n",
    "    cov_type=\"clustered\", clusters=data[\"market_ids\"]\n",
    ")\n",
    "print(iv_res.summary)\n",
    "\n",
    "# Coefs\n",
    "beta_x    = iv_res.params[\"x\"]\n",
    "alpha_p   = iv_res.params[\"prices\"]\n",
    "sigma_sat = iv_res.params[\"ln_within_sat\"]\n",
    "sigma_wir = iv_res.params[\"ln_within_wired\"]\n",
    "print(\"\\nEstimates:\")\n",
    "print(f\"Beta on x           = {beta_x:.4f}\")\n",
    "print(f\"Alpha on prices     = {alpha_p:.4f}\")\n",
    "print(f\"Sigma (satellite)   = {sigma_sat:.4f}\")\n",
    "print(f\"Sigma (wired)       = {sigma_wir:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab298222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE LATEX TABLE\n",
    "table_data = pd.DataFrame(\n",
    "    {\n",
    "        \"IV-2SLS\": [\n",
    "            float(iv_res.params[\"prices\"]),\n",
    "            float(iv_res.params[\"x\"]),\n",
    "            float(iv_res.params[\"ln_within_sat\"]),\n",
    "            float(iv_res.params[\"ln_within_wired\"]),\n",
    "        ],\n",
    "    },\n",
    "    index=[\n",
    "        r\"\\alpha (price)\",\n",
    "        r\"\\beta_1 (x)\",\n",
    "        r\"\\sigma_{satellite}\",\n",
    "        r\"\\sigma_{wired}\"\n",
    "    ],\n",
    ").astype(float)\n",
    "\n",
    "out_path = Path(\"latex/table_exercise_6.tex\").resolve()\n",
    "latex_str = table_data.to_latex(\n",
    "    index=True,\n",
    "    float_format=\"%.3f\",\n",
    "    column_format=\"lccc\",\n",
    "    caption=\"Nested logit IV-2SLS estimates\",\n",
    "    label=\"tab:exercise_6\",\n",
    "    escape=False\n",
    ")\n",
    "out_path.write_text(latex_str, encoding=\"utf-8\")\n",
    "print(f\"\\nLaTeX table written to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a707ca",
   "metadata": {},
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34fe22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"simulated_data.csv\")\n",
    "\n",
    "\n",
    "# ---------- grab estimated parameters from IV ----------\n",
    "alpha_hat      = float(iv_res.params.get(\"prices\", np.nan))\n",
    "sigma_sat_hat  = float(iv_res.params.get(\"ln_within_sat\", np.nan))\n",
    "sigma_wir_hat  = float(iv_res.params.get(\"ln_within_wired\", np.nan))\n",
    "\n",
    "# ---------- prep data ----------\n",
    "eps = 1e-12\n",
    "df[\"shares\"]  = df[\"shares\"].astype(float).clip(lower=eps)\n",
    "df[\"prices\"]  = df.get(\"prices\", df.get(\"price\")).astype(float)\n",
    "df[\"is_satellite\"] = df[\"is_satellite\"].astype(int)\n",
    "df[\"is_wired\"]     = df[\"is_wired\"].astype(int)\n",
    "\n",
    "# market nest totals and within-nest shares\n",
    "df[\"S_sat\"] = df.groupby(\"market_ids\")[\"shares\"].transform(\n",
    "    lambda x: (x * df.loc[x.index, \"is_satellite\"]).sum()\n",
    ").clip(lower=eps)\n",
    "df[\"S_wir\"] = df.groupby(\"market_ids\")[\"shares\"].transform(\n",
    "    lambda x: (x * df.loc[x.index, \"is_wired\"]).sum()\n",
    ").clip(lower=eps)\n",
    "\n",
    "print(df[[\"S_sat\", \"S_wir\"]].describe())\n",
    "print(df[[\"shares\", \"S_sat\", \"S_wir\"]].head())\n",
    "\n",
    "df[\"s_within\"] = np.where(df[\"is_satellite\"]==1,\n",
    "                          df[\"shares\"]/df[\"S_sat\"],\n",
    "                          df[\"shares\"]/df[\"S_wir\"])\n",
    "\n",
    "\n",
    "# ---------- (1) own-price elasticities ----------\n",
    "def own_elasticity(alpha, sigma_sat, sigma_wir,df):\n",
    "    sig = np.where(df[\"is_satellite\"]==1, sigma_sat, sigma_wir)\n",
    "    return -alpha * df[\"prices\"] * (1 - sig) * (1 - df[\"s_within\"])\n",
    "\n",
    "def compute_true_elasticities(df, R=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Compute true own-price elasticities for each product-market pair.\n",
    "    df must contain: market_id, product_id, x, price, xi, is_satellite, is_wired\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    elasticities = []\n",
    "\n",
    "    # draw random consumer tastes (heterogeneity)\n",
    "    beta_sat_i = rng.normal(loc=4.0, scale=1.0, size=R)\n",
    "    beta_wir_i = rng.normal(loc=4.0, scale=1.0, size=R)\n",
    "\n",
    "    for mkt, mkt_df in df.groupby(\"market_ids\"):\n",
    "        x = mkt_df[\"x\"].to_numpy()\n",
    "        p = mkt_df[\"prices\"].to_numpy()\n",
    "        xi = mkt_df[\"xi\"].to_numpy()\n",
    "        is_sat = mkt_df[\"is_satellite\"].to_numpy()\n",
    "        is_wir = mkt_df[\"is_wired\"].to_numpy()\n",
    "\n",
    "        J = len(x)\n",
    "        v = np.zeros((R, J))  # deterministic utility part for each consumer\n",
    "\n",
    "        for j in range(J):\n",
    "            v[:, j] = (\n",
    "                TRUE_BETA1 * x[j]\n",
    "                + beta_sat_i * is_sat[j]\n",
    "                + beta_wir_i * is_wir[j]\n",
    "                + TRUE_ALPHA * p[j]\n",
    "                + xi[j]\n",
    "            )\n",
    "\n",
    "        # choice probabilities for each consumer (softmax)\n",
    "        exp_v = np.exp(v)\n",
    "        denom = 1 + exp_v.sum(axis=1, keepdims=True)  # include outside option\n",
    "        s_ijt = exp_v / denom  # shape (R, J)\n",
    "\n",
    "        # aggregate (average) market shares\n",
    "        s_jt = s_ijt.mean(axis=0)  # (J,)\n",
    "\n",
    "        # derivative term E_i[s_ijt(1 - s_ijt)]\n",
    "        deriv_term = (s_ijt * (1 - s_ijt)).mean(axis=0)  # (J,)\n",
    "\n",
    "        # own-price elasticities\n",
    "        elasticities_jt = TRUE_ALPHA * deriv_term * (p / s_jt)\n",
    "\n",
    "        for j, e in enumerate(elasticities_jt):\n",
    "            elasticities.append({\n",
    "                \"market_ids\": mkt,\n",
    "                \"product_is\": mkt_df.iloc[j][\"product_ids\"],\n",
    "                \"elasticity_true\": e\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(elasticities)\n",
    "\n",
    "\n",
    "\n",
    "elasticities  = compute_true_elasticities(df)\n",
    "df[\"elasticity_true\"] = elasticities[\"elasticity_true\"]\n",
    "df[\"elasticity_est\"]  = own_elasticity(alpha_hat,  sigma_sat_hat,  sigma_wir_hat, df)\n",
    "\n",
    "elasticity_table = df[[\"product_ids\", \"elasticity_true\", \"elasticity_est\"]].copy()\n",
    "elasticity_table.to_latex(\n",
    "    \"Latex/table_elasticities.tex\",\n",
    "    index=False, float_format=\"%.4f\",\n",
    "    caption=\"True vs. Estimated Own-Price Elasticities\",\n",
    "    label=\"tab:elasticities\"\n",
    ")\n",
    "\n",
    "# ---------- (2) diversion matrices ----------\n",
    "# Standard nested-logit diversion shares:\n",
    "# same nest: D_{ij} = s_j / (S_g - s_i)\n",
    "# other nest: D_{ij} = s_j / (1 - S_g)\n",
    "def diversion_matrix_for_market(dfm):\n",
    "    s = dfm[\"shares\"].to_numpy()\n",
    "    is_sat = dfm[\"is_satellite\"].to_numpy().astype(bool)\n",
    "    J = len(dfm)\n",
    "    D = np.zeros((J, J))\n",
    "    S_sat = s[is_sat].sum()\n",
    "    S_wir = s[~is_sat].sum()\n",
    "    for i in range(J):\n",
    "        same = is_sat == is_sat[i]\n",
    "        Sg   = S_sat if is_sat[i] else S_wir\n",
    "        for j in range(J):\n",
    "            if i == j: \n",
    "                continue\n",
    "            if same[j]:\n",
    "                denom = max(Sg - s[i], eps)\n",
    "                D[i, j] = s[j] / denom\n",
    "            else:\n",
    "                denom = max(1.0 - Sg, eps)\n",
    "                D[i, j] = s[j] / denom\n",
    "    return D\n",
    "\n",
    "# pick one representative market (or loop over markets and average if you prefer)\n",
    "mkt0 = df[\"market_ids\"].iloc[0]\n",
    "dfm  = df[df[\"market_ids\"] == mkt0].copy()\n",
    "prod_labels = dfm[\"product_ids\"].astype(str).to_list()\n",
    "\n",
    "D_true = diversion_matrix_for_market(dfm)      # uses observed (true) shares\n",
    "D_est  = diversion_matrix_for_market(dfm)      # implied by nested-logit proportional diversion given observed shares\n",
    "\n",
    "# (If you want model-predicted shares to build D_est, plug those in instead of observed shares.)\n",
    "\n",
    "div_true_df = pd.DataFrame(D_true, index=prod_labels, columns=prod_labels)\n",
    "div_est_df  = pd.DataFrame(D_est,  index=prod_labels, columns=prod_labels)\n",
    "\n",
    "div_true_df.to_latex(\n",
    "    \"latex/table_diversion_true.tex\",\n",
    "    float_format=\"%.3f\",\n",
    "    caption=f\"True Diversion Ratios (Market {mkt0})\",\n",
    "    label=\"tab:diversion_true\"\n",
    ")\n",
    "div_est_df.to_latex(\n",
    "    \"latex/table_diversion_est.tex\",\n",
    "    float_format=\"%.3f\",\n",
    "    caption=f\"Estimated Diversion Ratios (Nested Logit, Market {mkt0})\",\n",
    "    label=\"tab:diversion_est\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame({\n",
    "    \"Parameter\": [\"$\\\\alpha (Price)$\", \"$\\\\sigma_{sat}$\", \"$\\\\sigma_{wir}$\",\n",
    "                  \"Mean Elasticity\"],\n",
    "    \"True Value\": [TRUE_ALPHA, TRUE_SD3, TRUE_SD2,\n",
    "                   df[\"elasticity_true\"].mean()],\n",
    "    \"Estimated\": [alpha_hat, sigma_sat_hat, sigma_wir_hat,\n",
    "                   df[\"elasticity_est\"].mean()],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237a15f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87069413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- (3) compact summary as  ----------\n",
    "summary_table = pd.DataFrame({\n",
    "    \"Parameter\": [\"Alpha (Price)\", \"Sigma_sat\", \"Sigma_wir\",\n",
    "                  \"Mean Elasticity\"],\n",
    "    \"True Value\": [TRUE_ALPHA, TRUE_SD3, TRUE_SD2,\n",
    "                   df[\"elasticity_true\"].mean()],\n",
    "    \"Estimated\": [alpha_hat, sigma_sat_hat, sigma_wir_hat,\n",
    "                   df[\"elasticity_est\"].mean()],\n",
    "})\n",
    "summary_table.to_latex(\n",
    "    \"latex/table_exercise_7.tex\",\n",
    "    index=False, float_format=\"%.4f\",\n",
    "    caption=\"Summary: True vs. Estimated Parameters and Elasticities\",\n",
    "    label=\"tab:exercise_7\"\n",
    ")\n",
    "\n",
    "print(\"Saved tables:\")\n",
    "print(\"  - table_elasticities.tex\")\n",
    "print(\"  - table_diversion_true.tex\")\n",
    "print(\"  - table_diversion_est.tex\")\n",
    "print(\"  - table_exercise_7.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b057369c",
   "metadata": {},
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fed261",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_8 = pd.read_csv(\"simulated_data.csv\")\n",
    "data_8[\"firm_ids\"] = data_8[\"product_ids\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70f52233",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyblp as blp\n",
    "\n",
    "# ---- 0) Data prep / renaming ----\n",
    "prod = data_8.copy()\n",
    "\n",
    "# Keep price in X1 even though it’s endogenous—pyBLP handles that via instruments you attach.\n",
    "form_X1 = blp.Formulation(\"1 + prices + x + is_satellite\")\n",
    "form_X2 = blp.Formulation(\"0 + is_satellite\")          # constant marginal costs\n",
    "form_X3 = blp.Formulation(\"1 + w\")  # no nonlinear utility characteristicsù\n",
    "\n",
    "# ---- 2) Core BLP instruments ----\n",
    "Z_blp = blp.build_blp_instruments(\n",
    "    blp.Formulation(\"0 + x + is_satellite + is_wired\"),\n",
    "    prod,\n",
    ")\n",
    "Z_blp = Z_blp[:, (Z_blp.shape[1]//2):]  # drop empty columns if any\n",
    "print(\"BLP demand instruments shape:\", Z_blp.shape)\n",
    "print(Z_blp[:5])  # first 5 rows\n",
    "Z_diff = blp.build_differentiation_instruments(\n",
    "    blp.Formulation(\"0 + x\"),\n",
    "    prod\n",
    ")\n",
    "\n",
    "# ---- 4) Nested-logit extras: same-nest “quality index” sums ----\n",
    "# market-level totals by nest\n",
    "prod[\"x_sat_sum_mkt\"] = prod.groupby(\"market_ids\").apply(\n",
    "    lambda d: (d[\"x\"] * d[\"is_satellite\"]).sum()\n",
    ").reindex(prod.index, level=0).to_numpy() if isinstance(prod.index, pd.MultiIndex) \\\n",
    " else prod.groupby(\"market_ids\")[\"x\"].transform(lambda s: (s * prod.loc[s.index, \"is_satellite\"]).sum())\n",
    "\n",
    "prod[\"x_wir_sum_mkt\"] = prod.groupby(\"market_ids\").apply(\n",
    "    lambda d: (d[\"x\"] * d[\"is_wired\"]).sum()\n",
    ").reindex(prod.index, level=0).to_numpy() if isinstance(prod.index, pd.MultiIndex) \\\n",
    " else prod.groupby(\"market_ids\")[\"x\"].transform(lambda s: (s * prod.loc[s.index, \"is_wired\"]).sum())\n",
    "\n",
    "# sum of x in same nest excluding j\n",
    "prod[\"x_same_nest_excl\"] = np.where(\n",
    "    prod[\"is_satellite\"] == 1,\n",
    "    (prod[\"x_sat_sum_mkt\"] - prod[\"x\"]),\n",
    "    (prod[\"x_wir_sum_mkt\"] - prod[\"x\"])\n",
    ")\n",
    "# ---- 5) Stack the instrument blocks for demand ----\n",
    "# Own exogenous shifters for j: x_jt, is_satellite_jt, is_wired_jt, and cost shifter w_jt\n",
    "X_own = prod[[\"x\", \"is_satellite\", \"w\"]].to_numpy()\n",
    "\n",
    "# Concatenate: own shifters + BLP + differentiation + same-nest sums\n",
    "Z_demand = np.hstack([X_own, Z_blp, Z_diff, prod[[\"x_same_nest_excl\"]].to_numpy()]).astype(float)\n",
    "\n",
    "# 1) drop near-constant cols\n",
    "eps = 1e-10\n",
    "stds = Z_demand.std(axis=0)\n",
    "keep = stds > eps\n",
    "Z_demand = Z_demand[:, keep]\n",
    "\n",
    "# Attach as object-dtype list so each row is an array (pyBLP convention)\n",
    "prod = prod.copy()\n",
    "# Expand instruments for inspection (Julia style)\n",
    "k_d = Z_demand.shape[1]\n",
    "colsD = [f\"demand_instruments{j}\" for j in range(k_d)]\n",
    "df_d = pd.DataFrame(Z_demand, columns=colsD)\n",
    "\n",
    "# Supply instrument: just x\n",
    "k_s = Z_diff.shape[1]\n",
    "colsS = [f\"supply_instruments{j}\" for j in range(k_s)]\n",
    "df_s = pd.DataFrame(Z_diff, columns=colsS)\n",
    "\n",
    "# Merge into product_data\n",
    "product_data = pd.concat([prod, df_d, df_s], axis=1)\n",
    "\n",
    "integration = blp.Integration('product', size=20)\n",
    "sigma0 = np.array([[0.1]], dtype=float)   # starting value\n",
    "\n",
    "# You can now pass `prod` to pyBLP. For example:\n",
    "problem = blp.Problem(product_formulations=(form_X1, form_X2), integration=integration, product_data=product_data, costs_type=\"log\")\n",
    "results = problem.solve(sigma=sigma0, method=\"2s\", optimization=pyblp.Optimization(\"l-bfgs-b\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac29232",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data = data_8.copy()\n",
    "product_data.rename(columns={\n",
    "    \"is_satellite\": \"satellite\",\n",
    "    \"is_wired\": \"wired\"\n",
    "}, inplace=True)\n",
    "print(product_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "blp_all = np.asarray(pyblp.build_blp_instruments(pyblp.Formulation(\"0 + x + satellite + wired\"), product_data))\n",
    "K = blp_all.shape[1] // 2\n",
    "blp_rival = blp_all[:, K:]\n",
    "\n",
    "diff_iv = np.asarray(pyblp.build_differentiation_instruments(pyblp.Formulation(\"0 + x\"), product_data))\n",
    "\n",
    "# Same-nest quality index: sum of x within the same technology (excluding self)\n",
    "same_nest_x = np.zeros(product_data.shape[0])\n",
    "for t in np.unique(product_data[\"market_ids\"]):\n",
    "    idx = np.where(product_data[\"market_ids\"] == t)[0]\n",
    "    sat_mask = product_data.loc[idx, \"satellite\"].to_numpy() == 1\n",
    "    wir_mask = product_data.loc[idx, \"wired\"].to_numpy() == 1\n",
    "    x_sat = product_data.loc[idx[sat_mask], \"x\"].to_numpy()\n",
    "    x_wir = product_data.loc[idx[wir_mask], \"x\"].to_numpy()\n",
    "    same_nest_x[idx[sat_mask]] = (x_sat.sum() - x_sat)\n",
    "    same_nest_x[idx[wir_mask]] = (x_wir.sum() - x_wir)\n",
    "\n",
    "xcol = product_data[\"x\"].to_numpy().reshape(-1, 1)\n",
    "wcol = product_data[\"w\"].to_numpy().reshape(-1, 1)\n",
    "satc = product_data[\"satellite\"].to_numpy().reshape(-1, 1)\n",
    "wirc = product_data[\"wired\"].to_numpy().reshape(-1, 1)\n",
    "sncol = same_nest_x.reshape(-1, 1)\n",
    "\n",
    "Zraw = np.hstack([blp_rival, diff_iv, sncol, xcol, wcol, satc, wirc])\n",
    "\n",
    "# Drop near-constant columns, then take a full column rank subset with QR\n",
    "stds = Zraw.std(axis=0)\n",
    "keep = np.where(stds > 1e-10)[0]\n",
    "Z1 = Zraw[:, keep]\n",
    "\n",
    "# Rank-revealing QR\n",
    "Q, R = np.linalg.qr(Z1, mode=\"reduced\")\n",
    "diagR = np.abs(np.diag(R))\n",
    "r = np.where(diagR > 1e-10)[0].size\n",
    "if r > 0:\n",
    "    idx_cols = np.arange(r)  # after QR with 'reduced', first r columns are independent\n",
    "    Z = Z1[:, idx_cols]\n",
    "else:\n",
    "    Z = np.zeros((Z1.shape[0], 0))\n",
    "\n",
    "# Attach instruments\n",
    "k_d = Z.shape[1]\n",
    "df_d = pd.DataFrame(Z, columns=[f\"demand_instruments{j}\" for j in range(k_d)])\n",
    "df_s = pd.DataFrame(xcol, columns=[\"supply_instruments0\"])  # x excluded from costs except via w\n",
    "product_data = pd.concat([product_data, df_d, df_s], axis=1)\n",
    "\n",
    "# Model formulations:\n",
    "#  - Utility: intercept + prices + x + satellite  (omit wired to avoid perfect partition)\n",
    "#  - One random coefficient on satellite\n",
    "#  - Log marginal cost: intercept + w\n",
    "X1 = pyblp.Formulation(\"1 + prices + x + satellite \")\n",
    "X2 = pyblp.Formulation(\"0 + satellite \")\n",
    "X3 = pyblp.Formulation(\"1 + w\")\n",
    "\n",
    "integ = pyblp.Integration(\"halton\", 500)\n",
    "sigma0 = np.array([[0.5]])\n",
    "\n",
    "\n",
    "problem_d  = pyblp.Problem((X1, X2), product_data, integration=integ, add_exogenous=False)\n",
    "problem_js = pyblp.Problem((X1, X2, X3), product_data, integration=integ,\n",
    "                        costs_type=\"log\", add_exogenous=False)\n",
    "\n",
    "\n",
    "opt_quiet = pyblp.Optimization(\"l-bfgs-b\", {\"disp\": False})\n",
    "\n",
    "\n",
    "    # Demand-only\n",
    "\n",
    "res_demand = problem_d.solve(\n",
    "            sigma=sigma0,\n",
    "            method=\"2s\",\n",
    "            optimization=opt_quiet,\n",
    "        )\n",
    "\n",
    "    # Joint demand + supply\n",
    "\n",
    "res_joint = problem_js.solve(\n",
    "            sigma=np.array(res_demand.sigma),\n",
    "            beta=np.array(res_demand.beta),\n",
    "            method=\"2s\",\n",
    "            optimization=opt_quiet,\n",
    "        )\n",
    "\n",
    "# Feasible optimal IV\n",
    "\n",
    "oi = res_joint.compute_optimal_instruments(method=\"approximate\")\n",
    "problem_opt = oi.to_problem()\n",
    "res_optimal_iv = problem_opt.solve(\n",
    "        sigma=np.array(res_joint.sigma),\n",
    "        beta=np.array(res_joint.beta),\n",
    "        method=\"2s\",\n",
    "        optimization=opt_quiet,\n",
    "    )\n",
    "\n",
    "# Helper to pull estimates and SEs\n",
    "def get_beta(res, name):\n",
    "    labels = list(res.beta_labels)\n",
    "    if name in labels:\n",
    "        i = labels.index(name)\n",
    "        return float(np.array(res.beta)[i]), float(np.array(res.beta_se)[i])\n",
    "    return np.nan, np.nan\n",
    "\n",
    "def get_sigma(res):\n",
    "    s = np.array(res.sigma)\n",
    "    se = np.array(res.sigma_se)\n",
    "    return float(s[0, 0]), float(se[0, 0])\n",
    "\n",
    "# Summaries\n",
    "bx_d, se_bx_d = get_beta(res_demand, \"x\")\n",
    "ap_d, se_ap_d = get_beta(res_demand, \"prices\")\n",
    "bsat_d, se_bsat_d = get_beta(res_demand, \"satellite\")\n",
    "ssat_d, se_ssat_d = get_sigma(res_demand)\n",
    "\n",
    "bx_js, se_bx_js = get_beta(res_joint, \"x\")\n",
    "ap_js, se_ap_js = get_beta(res_joint, \"prices\")\n",
    "bsat_js, se_bsat_js = get_beta(res_joint, \"satellite\")\n",
    "ssat_js, se_ssat_js = get_sigma(res_joint)\n",
    "\n",
    "bx_o, se_bx_o = get_beta(res_optimal_iv, \"x\")\n",
    "ap_o, se_ap_o = get_beta(res_optimal_iv, \"prices\")\n",
    "bsat_o, se_bsat_o = get_beta(res_optimal_iv, \"satellite\")\n",
    "ssat_o, se_ssat_o = get_sigma(res_optimal_iv)\n",
    "\n",
    "print(\"\\npyBLP summaries (estimate (se))\")\n",
    "def fmt(x): return f\"{x:.3f}\"\n",
    "print(f\" Demand-only    : beta_x {fmt(bx_d)} ({fmt(se_bx_d)}), alpha {fmt(ap_d)} ({fmt(se_ap_d)}), \"\n",
    "        f\"beta_sat {fmt(bsat_d)} ({fmt(se_bsat_d)}), sigma_sat {fmt(ssat_d)} ({fmt(se_ssat_d)})\")\n",
    "print(f\" Joint (supply) : beta_x {fmt(bx_js)} ({fmt(se_bx_js)}), alpha {fmt(ap_js)} ({fmt(se_ap_js)}), \"\n",
    "        f\"beta_sat {fmt(bsat_js)} ({fmt(se_bsat_js)}), sigma_sat {fmt(ssat_js)} ({fmt(se_ssat_js)})\")\n",
    "print(f\" Opt. IV        : beta_x {fmt(bx_o)} ({fmt(se_bx_o)}), alpha {fmt(ap_o)} ({fmt(se_ap_o)}), \"\n",
    "        f\"beta_sat {fmt(bsat_o)} ({fmt(se_bsat_o)}), sigma_sat {fmt(ssat_o)} ({fmt(se_ssat_o)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- list the models in order ---\n",
    "models = {\n",
    "    \"Demand Only\": res_demand,\n",
    "    \"Joint Demand + Supply\": res_joint,\n",
    "    \"Optimal IV\": res_optimal_iv,\n",
    "}\n",
    "# --- collect coefficients and s.e. ---\n",
    "rows = []\n",
    "for label, res in models.items():\n",
    "    for idx, name in enumerate(res.beta_labels):\n",
    "        val = res.beta[idx][0]\n",
    "        se  = res.beta_se[idx][0]\n",
    "        rows.append({\n",
    "            \"Parameter\": name,\n",
    "            \"Model\": label,\n",
    "            \"Estimate\": val,\n",
    "            \"Std. Error\": se\n",
    "        })\n",
    "\n",
    "df_table = pd.DataFrame(rows)\n",
    "# --- arrange parameters vertically with s.e. below (nice two-line format) ---\n",
    "def format_est_se(est, se):\n",
    "    return f\"{est:.4f}\\n({se:.4f})\"\n",
    "\n",
    "table_formatted = (\n",
    "    df_table\n",
    "    .assign(cell=df_table.apply(lambda r: format_est_se(r[\"Estimate\"], r[\"Std. Error\"]), axis=1))\n",
    "    .pivot(index=\"Parameter\", columns=\"Model\", values=\"cell\")\n",
    ")\n",
    "\n",
    "# --- export to LaTeX ---\n",
    "out_path = Path(\"Latex/table_exercise_8.tex\")\n",
    "latex_str = table_formatted.to_latex(\n",
    "    float_format=\"%.4f\",\n",
    "    caption=\"Estimates of Demand Parameters and Standard Errors Across Specifications\",\n",
    "    label=\"tab:exercise_8\",\n",
    "    escape=False,\n",
    "    multicolumn=True,\n",
    ")\n",
    "\n",
    "out_path.write_text(latex_str, encoding=\"utf-8\")\n",
    "print(f\"✅ Saved to {out_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41588ab7",
   "metadata": {},
   "source": [
    "### 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f167392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_beta = np.array([\n",
    "    0.0,   # intercept in utility (not specified in your DGP; set 0)\n",
    "    1.0,   # coefficient on x\n",
    "    4.0,   # mean taste for satellite\n",
    "   -2.0    # price coefficient alpha\n",
    "])\n",
    "\n",
    "# sigma corresponds to X2 ('satellite', 'wired')\n",
    "# You said beta_i^(2) ~ N(4,1) and beta_i^(3) ~ N(4,1),\n",
    "# meaning std dev 1, uncorrelated.\n",
    "true_sigma = np.array([1.0])\n",
    "\n",
    "# gamma are the marginal cost parameters for '1 + w'\n",
    "# ln mc = gamma0 + gamma1 * w + omega/8\n",
    "true_gamma = np.array([\n",
    "    0.5,   # gamma0\n",
    "    0.25   # gamma1\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Solve the model at the TRUE parameters\n",
    "# ------------------------------------------------------------\n",
    "# This solves for the delta (mean utilities), the markups, etc.,\n",
    "# taking your prices and shares as equilibrium outcomes consistent\n",
    "# with those parameters.\n",
    "\n",
    "results_true = problem_js.solve(\n",
    "    sigma=true_sigma,\n",
    "    beta=true_beta,\n",
    "    gamma=true_gamma,   # supply side parameters\n",
    "    method='1s'         # fast contraction\n",
    ")\n",
    "print(\"\\nSolving at TRUE parameters:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_true = results_true.compute_elasticities(market_id=1)\n",
    "E_est  = res_joint.compute_elasticities(market_id=1)\n",
    "\n",
    "own_true = np.diag(E_true)\n",
    "own_est  = np.diag(E_est)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"Product\": np.arange(1, J+1),\n",
    "    \"True own-price elasticity\": own_true,\n",
    "    \"Estimated own-price elasticity\": own_est\n",
    "})\n",
    "\n",
    "comparison.to_latex(\n",
    "    \"latex/table_exercise_9.tex\",\n",
    "    index=False,\n",
    "    float_format=\"%.4f\",\n",
    "    caption=\"True vs. Estimated Own-Price Elasticities at Market 1\",\n",
    "    label=\"tab:exercise_9\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diversions_est = res_joint.compute_diversion_ratios()\n",
    "diversions_true = results_true.compute_diversion_ratios()\n",
    "\n",
    "# Option 1: simple unweighted average\n",
    "avg_div = diversions_est.groupby([\"from_ids\", \"to_ids\"])[\"diversion\"].mean().reset_index()\n",
    "\n",
    "# Option 2: share-weighted average (if shares in product_data)\n",
    "diversions_est = diversions_est.merge(product_data[[\"market_ids\",\"product_ids\",\"shares\"]],\n",
    "                left_on=[\"market_ids\",\"from_ids\"],\n",
    "                right_on=[\"market_ids\",\"product_ids\"],\n",
    "                how=\"left\")\n",
    "avg_div_weighted_est = (\n",
    "    diversions_est.groupby([\"from_ids\", \"to_ids\"])\n",
    "       .apply(lambda g: np.average(g[\"diversion\"], weights=g[\"shares\"]))\n",
    "       .reset_index(name=\"diversion_weighted\")\n",
    ")\n",
    "\n",
    "avg_div = diversions_true.groupby([\"from_ids\", \"to_ids\"])[\"diversion\"].mean().reset_index()\n",
    "\n",
    "# Option 2: share-weighted average (if shares in product_data)\n",
    "diversions_true = diversions_true.merge(product_data[[\"market_ids\",\"product_ids\",\"shares\"]],\n",
    "                left_on=[\"market_ids\",\"from_ids\"],\n",
    "                right_on=[\"market_ids\",\"product_ids\"],\n",
    "                how=\"left\")\n",
    "avg_div_weighted_true = (\n",
    "    diversions_true.groupby([\"from_ids\", \"to_ids\"])\n",
    "       .apply(lambda g: np.average(g[\"diversion\"], weights=g[\"shares\"]))\n",
    "       .reset_index(name=\"diversion_weighted\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "div_comparison_df_true = pd.DataFrame(avg_div_weighted_true)\n",
    "div_comparison_df_est  = pd.DataFrame(avg_div_weighted_est)\n",
    "\n",
    "div_comparison_df_true.to_latex(\n",
    "    \"latex/table_diversion_9_true.tex\",\n",
    "    index=False,\n",
    "    float_format=\"%.4f\",\n",
    "    caption=\"True Diversion Ratios\",\n",
    "    label=\"tab:diversion_9_true\"\n",
    ")\n",
    "\n",
    "div_comparison_df_est.to_latex(\n",
    "    \"latex/table_diversion_9_est.tex\",\n",
    "    index=False,\n",
    "    float_format=\"%.4f\",\n",
    "    caption=\"Estimated Diversion Ratios\",\n",
    "    label=\"tab:diversion_9_est\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8701ef",
   "metadata": {},
   "source": [
    "### 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385def98",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = res_joint.compute_costs()\n",
    "hhi = res_joint.compute_hhi()\n",
    "profits = res_joint.compute_profits(costs=costs)\n",
    "cs = res_joint.compute_consumer_surpluses()\n",
    "\n",
    "markups = res_joint.compute_markups(costs=costs)\n",
    "plt.hist(markups, bins=50);\n",
    "plt.legend([\"Markups\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d10646",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data_11 = product_data.copy()\n",
    "\n",
    "plt.hist(costs, bins=50);\n",
    "plt.legend([\"Marginal Costs\"]);\n",
    "product_data_11['merger_ids'] = product_data_11['firm_ids'].replace(2, 1)\n",
    "\n",
    "changed_prices_11 = res_joint.compute_prices(\n",
    "    firm_ids=product_data_11['merger_ids'],\n",
    "    costs=costs\n",
    ")\n",
    "print(changed_prices_11)\n",
    "\n",
    "changed_shares = res_joint.compute_shares(changed_prices_11)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e0a304",
   "metadata": {},
   "source": [
    "### 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34dcfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data_12 = product_data.copy()\n",
    "\n",
    "plt.hist(costs, bins=50);\n",
    "plt.legend([\"Marginal Costs\"]);\n",
    "product_data_12['merger_ids'] = product_data_12['firm_ids'].replace(3, 1)\n",
    "\n",
    "changed_prices_12 = res_joint.compute_prices(\n",
    "    firm_ids=product_data_12['merger_ids'],\n",
    "    costs=costs\n",
    ")\n",
    "print(changed_prices_12)\n",
    "\n",
    "changed_shares = res_joint.compute_shares(changed_prices_12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prices = product_data['prices'].values[:,None]  # shape (T*J,)\n",
    "\n",
    "# --- Merger 11 results (you already computed changed_prices_11) ---\n",
    "delta_11 = changed_prices_11 - base_prices  # price change after merger 11\n",
    "\n",
    "# --- Merger 12 results (you computed changed_prices_12 above) ---\n",
    "delta_12 = changed_prices_12 - base_prices  # price change after merger 12\n",
    "\n",
    "\n",
    "df_compare = pd.DataFrame({\n",
    "    'market_id': product_data['market_ids'].values,\n",
    "    'product_id': product_data['product_ids'].values,\n",
    "    'baseline_price': base_prices[:,0],\n",
    "    'post_merger_price_11': changed_prices_11[:,0],\n",
    "    'post_merger_price_12': changed_prices_12[:,0],\n",
    "    'delta_price_11': delta_11[:,0],\n",
    "    'delta_price_12': delta_12[:,0]\n",
    "})\n",
    "\n",
    "# Average across markets: one row per product_id\n",
    "avg_changes = df_compare.groupby('product_id')[['delta_price_11','delta_price_12']].mean()\n",
    "\n",
    "# Rename columns for clarity in the table\n",
    "avg_changes = avg_changes.rename(columns={\n",
    "    'delta_price_11': 'Avg ΔPrice: Merger 11',\n",
    "    'delta_price_12': 'Avg ΔPrice: Merger 12'\n",
    "})\n",
    "\n",
    "# Optional: add % changes too (across markets, average of %Δp)\n",
    "df_compare['pct_delta_11'] = delta_11 / base_prices * 100.0\n",
    "df_compare['pct_delta_12'] = delta_12 / base_prices * 100.0\n",
    "avg_pct_changes = df_compare.groupby('product_id')[['pct_delta_11','pct_delta_12']].mean()\n",
    "\n",
    "avg_pct_changes = avg_pct_changes.rename(columns={\n",
    "    'pct_delta_11': 'Avg %ΔPrice: Merger 11',\n",
    "    'pct_delta_12': 'Avg %ΔPrice: Merger 12'\n",
    "})\n",
    "\n",
    "# Final table: merge levels and round\n",
    "final_table = avg_changes.merge(\n",
    "    avg_pct_changes,\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ").round(4)\n",
    "\n",
    "# Give nicer product labels\n",
    "final_table.index.name = 'Product'\n",
    "final_table.reset_index(inplace=True)\n",
    "\n",
    "print(final_table)\n",
    "\n",
    "final_table.to_latex(\n",
    "    \"latex/table_exercise_12.tex\",\n",
    "    index=False,\n",
    "    float_format=\"%.4f\",\n",
    "    caption=\"Average Price Changes Due to Mergers\",\n",
    "    label=\"tab:exercise_12\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef9d53d",
   "metadata": {},
   "source": [
    "### 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b54554",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data_14 = product_data.copy()\n",
    "\n",
    "plt.hist(costs, bins=50);\n",
    "plt.legend([\"Marginal Costs\"]);\n",
    "product_data_14['merger_ids'] = product_data_14['firm_ids'].replace(2, 1)\n",
    "\n",
    "changed_prices_14 = res_joint.compute_prices(\n",
    "    firm_ids=product_data_14['merger_ids'],\n",
    "    costs=costs * 0.85\n",
    ")\n",
    "print(changed_prices_14)\n",
    "\n",
    "changed_shares = res_joint.compute_shares(changed_prices_14)\n",
    "\n",
    "\n",
    "changed_cs = res_joint.compute_consumer_surpluses(changed_prices_14)\n",
    "plt.hist(changed_cs - cs, bins=50);\n",
    "plt.legend([\"Consumer Surplus Changes\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_14 = changed_prices_14 - base_prices  # price change after merger 14\n",
    "\n",
    "\n",
    "df_compare_14 = pd.DataFrame({\n",
    "    'market_id': product_data['market_ids'].values,\n",
    "    'product_id': product_data['product_ids'].values,\n",
    "    'baseline_price': base_prices[:,0],\n",
    "    'post_merger_price_11': changed_prices_11[:,0],\n",
    "    'post_merger_price_12': changed_prices_12[:,0],\n",
    "    'post_merger_price_14': changed_prices_14[:,0],\n",
    "    'delta_price_11': delta_11[:,0],\n",
    "    'delta_price_12': delta_12[:,0],\n",
    "    'delta_price_14': delta_14[:,0]\n",
    "})\n",
    "\n",
    "# Average across markets: one row per product_id\n",
    "avg_changes = df_compare_14.groupby('product_id')[['delta_price_11','delta_price_12','delta_price_14']].mean()\n",
    "\n",
    "# Rename columns for clarity in the table\n",
    "avg_changes = avg_changes.rename(columns={\n",
    "    'delta_price_11': 'Avg ΔPrice: Merger 11',\n",
    "    'delta_price_12': 'Avg ΔPrice: Merger 12',\n",
    "    'delta_price_14': 'Avg ΔPrice: Merger 14'\n",
    "})\n",
    "\n",
    "# Optional: add % changes too (across markets, average of %Δp)\n",
    "df_compare_14['pct_delta_11'] = delta_11 / base_prices * 100.0\n",
    "df_compare_14['pct_delta_12'] = delta_12 / base_prices * 100.0\n",
    "df_compare_14['pct_delta_14'] = delta_14 / base_prices * 100.0\n",
    "avg_pct_changes = df_compare_14.groupby('product_id')[['pct_delta_11','pct_delta_12','pct_delta_14']].mean()\n",
    "\n",
    "avg_pct_changes = avg_pct_changes.rename(columns={\n",
    "    'pct_delta_11': 'Avg %ΔPrice: Merger 11',\n",
    "    'pct_delta_12': 'Avg %ΔPrice: Merger 12',\n",
    "    'pct_delta_14': 'Avg %ΔPrice: Merger 14'\n",
    "})\n",
    "\n",
    "# Final table: merge levels and round\n",
    "final_table = avg_changes.merge(\n",
    "    avg_pct_changes,\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ").round(4)\n",
    "\n",
    "# Give nicer product labels\n",
    "final_table.index.name = 'Product'\n",
    "final_table.reset_index(inplace=True)\n",
    "\n",
    "print(final_table)\n",
    "\n",
    "final_table.to_latex(\n",
    "    \"latex/table_exercise_14.tex\",\n",
    "    index=False,\n",
    "    float_format=\"%.4f\",\n",
    "    caption=\"Average Price Changes Due to Mergers\",\n",
    "    label=\"tab:exercise_14\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "profits = res_joint.compute_profits(costs=costs)\n",
    "cs = res_joint.compute_consumer_surpluses()\n",
    "total_welfare = np.sum(cs)\n",
    "print(\"Total Welfare (sum of profits and consumer surplus):\", total_welfare)\n",
    "out_path = Path(\"latex/scalars_exercise_15.tex\").resolve()\n",
    "latex_str = f\"\\\\newcommand{{\\\\TotalWelfare}}{{{total_welfare.sum():.3f}}}\\n\"\n",
    "out_path.write_text(latex_str, encoding=\"utf-8\")\n",
    "print(f\"\\nLaTeX scalar written to: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
